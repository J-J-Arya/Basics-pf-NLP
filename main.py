import streamlit as st
import nltk
from nltk.tokenize import TreebankWordTokenizer
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer
import string
from textblob import TextBlob  # ‚úÖ Added for spelling correction

# -------------------------------
# Download NLTK resources (only once)
# -------------------------------
nltk.download("punkt")
nltk.download("stopwords")
nltk.download("wordnet")

# -------------------------------
# Initialize tools
# -------------------------------
stop_words = set(stopwords.words("english"))
stemmer = PorterStemmer()
lemmatizer = WordNetLemmatizer()

# -------------------------------
# Streamlit App Configuration
# -------------------------------
st.set_page_config(page_title="üî§ NLP Playground", layout="centered")
st.title("üî§ NLP Text Preprocessing Playground")
st.write("Enter a sentence to clean, correct, tokenize, stem, and lemmatize.")

# -------------------------------
# Input
# -------------------------------
text_input = st.text_area("‚úè Enter your sentence:", height=150)

# -------------------------------
# Process Button
# -------------------------------
if st.button("üß™ Process"):
    if not text_input.strip():
        st.warning("Please enter some text.")
    else:
        # Step 1: Lowercase and remove punctuation
        cleaned = text_input.lower().translate(str.maketrans("", "", string.punctuation))
        st.markdown(f"üßπ Cleaned Text: `{cleaned}`")

        # Step 2: Spelling Correction (TextBlob)
        corrected_text = str(TextBlob(cleaned).correct())
        st.markdown(f"üìù Spelling Corrected: `{corrected_text}`")

        # Step 3: Tokenization
        tokenizer = TreebankWordTokenizer()
        tokens = tokenizer.tokenize(corrected_text)
        st.markdown(f"üî† Tokens: `{tokens}`")

        # Step 4: Remove Stopwords
        filtered = [word for word in tokens if word not in stop_words]
        st.markdown(f"‚õî Without Stopwords: `{filtered}`")

        # Step 5: Stemming
        stemmed = [stemmer.stem(word) for word in filtered]
        st.markdown(f"üå± Stemmed Words: `{stemmed}`")

        # Step 6: Lemmatization
        lemmatized = [lemmatizer.lemmatize(word) for word in filtered]
        st.markdown(f"üçã Lemmatized Words: `{lemmatized}`")
